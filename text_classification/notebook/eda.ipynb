{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 데이터 처리 라이브러리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 텍스트 전처리\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "from datetime import datetime\n",
    "\n",
    "# 경고 무시\n",
    "import warnings\n",
    "import os\n",
    "os.chdir('../')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 한글 폰트 설정 (matplotlib용)\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib\n",
    "\n",
    "# font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'  # 폰트 경로 설정\n",
    "# font = fm.FontProperties(fname=font_path).get_name()\n",
    "# matplotlib.rc('font', family=font)\n",
    "\n",
    "# GPU 사용 가능 여부 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"Device Name : {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# nltk 데이터 다운로드 (불용어 등 필요 시만 다운로드)\n",
    "nltk_data = {\n",
    "    \"stopwords\": \"corpora/stopwords.zip\",\n",
    "    \"punkt\": \"tokenizers/punkt.zip\"\n",
    "}\n",
    "for key, path in nltk_data.items():\n",
    "    try:\n",
    "        nltk.data.find(path)\n",
    "    except LookupError:\n",
    "        print(f\"Downloading {key}...\")\n",
    "        nltk.download(key)\n",
    "\n",
    "# tqdm for progress bars\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './dataset_sample'\n",
    "FEATURES = ['title', 'description', 'content', 'contentLength']\n",
    "\n",
    "os.chdir('/workspaces/recommender/text_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daangn = pd.read_csv(f'{DATA_PATH}/daangn-techblog.csv')[FEATURES]\n",
    "toss = pd.read_csv(f'{DATA_PATH}/toss-techblog.csv')[FEATURES]\n",
    "wooahan = pd.read_csv(f'{DATA_PATH}/wooahan-techblog.csv')[FEATURES]\n",
    "\n",
    "daangn[\"from\"] = \"daangn\"\n",
    "toss[\"from\"] = \"toss\"\n",
    "wooahan[\"from\"] = \"wooahan\"\n",
    "\n",
    "total_article = pd.concat([daangn, toss, wooahan], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_colors = {\n",
    "    'daangn': '#FF8B00',      # 당근마켓 오렌지\n",
    "    'toss': '#0056F6',        # 토스 블루\n",
    "    'wooahan': '#6BBE45'      # 우아한형제들 그린\n",
    "}\n",
    "\n",
    "# Calculate article counts and mean content length by company\n",
    "article_counts = total_article['from'].value_counts()\n",
    "mean_lengths = total_article.groupby('from')['contentLength'].mean()\n",
    "\n",
    "# Plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 8))\n",
    "\n",
    "# Subplot 1: Article Count\n",
    "colors = [brand_colors[idx] for idx in article_counts.index]\n",
    "axes[0].bar(article_counts.index, article_counts, color=colors)\n",
    "axes[0].set_title(\"회사 별 아티클 개수\")\n",
    "axes[0].set_ylabel(\"개수\")\n",
    "axes[0].bar_label(axes[0].containers[0], fmt='%d', label_type='edge', fontsize=10)  # Show counts on bars\n",
    "\n",
    "# Subplot 2: Mean Content Length\n",
    "colors = [brand_colors[idx] for idx in mean_lengths.index]\n",
    "axes[1].bar(mean_lengths.index, mean_lengths, color=colors)\n",
    "axes[1].set_title(\"회사 별 아티클 내용 평균 길이\")\n",
    "axes[1].set_ylabel(\"평균 길이 (글자수)\")\n",
    "axes[1].bar_label(axes[1].containers[0], fmt='%.1f', label_type='edge', fontsize=10)  # Show means on bars\n",
    "\n",
    "# Adjust layout\n",
    "plt.xlabel(\"출처\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample(sample, ext):\n",
    "    if isinstance(sample, str):\n",
    "        filename = f\"{ext}_output\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(sample)\n",
    "    else:\n",
    "        filename = f\"{sample['from'].iloc[0]}_{ext}\"\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(sample['content'].iloc[0])\n",
    "\n",
    "toss_sample = toss.sample()\n",
    "daangn_sample = daangn.sample()\n",
    "wooahan_sample = wooahan.sample()\n",
    "\n",
    "for sample in [toss_sample, daangn_sample, wooahan_sample]:\n",
    "   save_sample(sample, 'input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict\n",
    "from dataclasses import dataclass\n",
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "\n",
    "@dataclass\n",
    "class CodeBlock:\n",
    "    language: str\n",
    "    code: str\n",
    "    line_number: int  # Starting line number in the original text\n",
    "    indentation: int  # Level of indentation\n",
    "\n",
    "class TextProcessor:\n",
    "    def __init__(self, text: str):\n",
    "        self.raw_text = text\n",
    "        self.cleaned_text = \"\"\n",
    "        self.code_blocks = []\n",
    "        self.language_markers = {\n",
    "            'python': [\n",
    "                r'import\\s+[\\w\\s,]+',\n",
    "                r'def\\s+\\w+\\s*\\([^)]*\\)\\s*:',\n",
    "                r'class\\s+\\w+\\s*[:(]',\n",
    "                r'print\\s*\\(',\n",
    "                r'if\\s+__name__\\s*==\\s*[\\'\"]__main__[\\'\"]',\n",
    "                r'with\\s+.*?\\s*as\\s+\\w+:',\n",
    "                r'try:(?:\\s*except|\\s*finally)',\n",
    "                r'for\\s+\\w+\\s+in\\s+',\n",
    "                r'while\\s+.*?:'\n",
    "            ],\n",
    "            'javascript': [\n",
    "                r'function\\s+\\w+\\s*\\([^)]*\\)',\n",
    "                r'const\\s+\\w+\\s*=',\n",
    "                r'let\\s+\\w+\\s*=',\n",
    "                r'var\\s+\\w+\\s*=',\n",
    "                r'import\\s+.*?from',\n",
    "                r'=>',\n",
    "                r'console\\.',\n",
    "                r'module\\.exports',\n",
    "                r'export\\s+(?:default\\s+)?(?:function|class|const|let|var)'\n",
    "            ],\n",
    "            'java': [\n",
    "                r'public\\s+class',\n",
    "                r'private\\s+\\w+',\n",
    "                r'protected\\s+\\w+',\n",
    "                r'System\\.out\\.',\n",
    "                r'import\\s+java\\.',\n",
    "                r'@Override'\n",
    "            ],\n",
    "            'sql': [\n",
    "                r'SELECT\\s+.*?\\s+FROM',\n",
    "                r'INSERT\\s+INTO',\n",
    "                r'UPDATE\\s+.*?\\s+SET',\n",
    "                r'DELETE\\s+FROM',\n",
    "                r'CREATE\\s+TABLE',\n",
    "                r'ALTER\\s+TABLE',\n",
    "                r'DROP\\s+TABLE',\n",
    "                r'JOIN\\s+\\w+'\n",
    "            ],\n",
    "            'html': [\n",
    "                r'<(?:html|head|body|div|span|p|a|script|link|meta)',\n",
    "                r'</[a-z]+>',\n",
    "                r'class=[\"\\'].*?[\"\\']'\n",
    "            ],\n",
    "            'css': [\n",
    "                r'{\\s*[\\w-]+\\s*:',\n",
    "                r'@media',\n",
    "                r'@import',\n",
    "                r'\\.[a-zA-Z][\\w-]*\\s*{',\n",
    "                r'#[\\w-]+\\s*{'\n",
    "            ]\n",
    "        }\n",
    "        self.markdown_markers = {\n",
    "            'start': [\n",
    "                r'```\\w*',           # Code fence with optional language\n",
    "                r'~~~\\w*',           # Alternative code fence\n",
    "                r'(?:^|\\n)    ',     # Indented code block (4 spaces)\n",
    "                r'(?:^|\\n)\\t'        # Indented code block (tab)\n",
    "            ],\n",
    "            'end': [\n",
    "                r'```',\n",
    "                r'~~~',\n",
    "                r'\\n\\S'              # End of indentation\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    def detect_language(self, code: str) -> str:\n",
    "        \"\"\"Detect the programming language of a code block\"\"\"\n",
    "        \n",
    "        # Count matches for each language's patterns\n",
    "        language_scores = {}\n",
    "        \n",
    "        for language, patterns in self.language_markers.items():\n",
    "            score = 0\n",
    "            for pattern in patterns:\n",
    "                matches = re.finditer(pattern, code, re.IGNORECASE | re.MULTILINE)\n",
    "                score += sum(1 for _ in matches)\n",
    "            language_scores[language] = score\n",
    "        \n",
    "        # Return the language with highest score, or 'unknown' if no clear match\n",
    "        max_score = max(language_scores.values())\n",
    "        if max_score > 0:\n",
    "            for language, score in language_scores.items():\n",
    "                if score == max_score:\n",
    "                    return language\n",
    "        \n",
    "        return 'unknown'\n",
    "\n",
    "    def find_code_blocks(self) -> List[CodeBlock]:\n",
    "        \"\"\"Find all code blocks in the text\"\"\"\n",
    "        code_blocks = []\n",
    "        \n",
    "        # First look for markdown-style code blocks\n",
    "        line_number = 1\n",
    "        lines = self.raw_text.split('\\n')\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(lines):\n",
    "            line = lines[i]\n",
    "            \n",
    "            # Check for code fence markers\n",
    "            for start_pattern in self.markdown_markers['start']:\n",
    "                if re.match(start_pattern, line):\n",
    "                    code_lines = []\n",
    "                    start_line = line_number\n",
    "                    indentation = len(re.match(r'^\\s*', line).group())\n",
    "                    \n",
    "                    i += 1\n",
    "                    line_number += 1\n",
    "                    \n",
    "                    # Collect lines until end marker\n",
    "                    while i < len(lines):\n",
    "                        if any(re.match(end_pattern, lines[i]) for end_pattern in self.markdown_markers['end']):\n",
    "                            break\n",
    "                        code_lines.append(lines[i])\n",
    "                        i += 1\n",
    "                        line_number += 1\n",
    "                    \n",
    "                    if code_lines:\n",
    "                        code = '\\n'.join(code_lines)\n",
    "                        language = self.detect_language(code)\n",
    "                        code_blocks.append(CodeBlock(\n",
    "                            language=language,\n",
    "                            code=code,\n",
    "                            line_number=start_line,\n",
    "                            indentation=indentation\n",
    "                        ))\n",
    "            \n",
    "            i += 1\n",
    "            line_number += 1\n",
    "        \n",
    "        # Then look for language-specific patterns\n",
    "        text_without_markdown = re.sub(r'```.*?```', '', self.raw_text, flags=re.DOTALL)\n",
    "        for language, patterns in self.language_markers.items():\n",
    "            for pattern in patterns:\n",
    "                matches = re.finditer(pattern, text_without_markdown, re.MULTILINE)\n",
    "                for match in matches:\n",
    "                    # Get the context around the match\n",
    "                    start = match.start()\n",
    "                    # Find the beginning of the code block\n",
    "                    block_start = text_without_markdown.rfind('\\n', 0, start) + 1\n",
    "                    # Find the end of the code block\n",
    "                    block_end = text_without_markdown.find('\\n\\n', start)\n",
    "                    if block_end == -1:\n",
    "                        block_end = len(text_without_markdown)\n",
    "                    \n",
    "                    code = text_without_markdown[block_start:block_end].strip()\n",
    "                    \n",
    "                    # Only add if it's not already part of a detected code block\n",
    "                    if not any(code in block.code for block in code_blocks):\n",
    "                        line_number = text_without_markdown[:start].count('\\n') + 1\n",
    "                        indentation = len(re.match(r'^\\s*', code).group())\n",
    "                        code_blocks.append(CodeBlock(\n",
    "                            language=language,\n",
    "                            code=code,\n",
    "                            line_number=line_number,\n",
    "                            indentation=indentation\n",
    "                        ))\n",
    "        \n",
    "        return code_blocks\n",
    "\n",
    "    def remove_html(self):\n",
    "        \"\"\"Remove HTML content and decode HTML entities\"\"\"\n",
    "        soup = BeautifulSoup(self.raw_text, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "        text = html.unescape(text)\n",
    "        self.cleaned_text = text\n",
    "\n",
    "    def clean_whitespace(self):\n",
    "        \"\"\"Clean up excessive whitespace\"\"\"\n",
    "        # Replace multiple newlines with double newline\n",
    "        split_text = re.split(r'\\n                \\n            \\n                    \\n                    \\n                                    \\n                        ', self.cleaned_text)\n",
    "        if len(split_text) > 1:\n",
    "            self.cleaned_text = split_text[0]\n",
    "        self.cleaned_text = re.sub(r'\\n{3,}', '\\n\\n', self.cleaned_text)\n",
    "        # Replace multiple spaces with single space\n",
    "        self.cleaned_text = re.sub(r'\\s{2,}', ' ', self.cleaned_text)\n",
    "        # Clean up whitespace around punctuation\n",
    "        self.cleaned_text = re.sub(r'\\s+([.,!?])', r'\\1', self.cleaned_text)\n",
    "\n",
    "    def process_code_blocks(self):\n",
    "        \"\"\"Wrap detected code blocks in <code> tags\"\"\"\n",
    "        for block in self.code_blocks:\n",
    "            code_block_html = f'<code {block.language}>{block.code}</code>'\n",
    "            self.cleaned_text = self.cleaned_text.replace(block.code, code_block_html)\n",
    "\n",
    "    def split_text(self):\n",
    "        \"\"\"Split Special Text for extract useful article\"\"\"\n",
    "        \n",
    "        # Daangn Special Text : Published in (Medium 특성)\n",
    "        # Toss Special Text : 홈페이지회사소개채용고객센터  \n",
    "        # Wooahan Special Text : {{sub.name}}\n",
    "\n",
    "        if 'Published in' in self.cleaned_text:\n",
    "            self.cleaned_text = self.cleaned_text.split('Published in')[1]\n",
    "        \n",
    "        if '홈페이지회사소개채용고객센터' in self.cleaned_text:\n",
    "            self.cleaned_text = self.cleaned_text.split('홈페이지회사소개채용고객센터')[0]\n",
    "            self.cleaned_text = self.cleaned_text.split('댓글 관련 문의')[0]\n",
    "        \n",
    "        if '{{sub.name}}' in self.cleaned_text:\n",
    "            self.cleaned_text = self.cleaned_text.split('{{sub.name}}')[1]\n",
    "\n",
    "\n",
    "    def preprocess(self) -> str:\n",
    "        \"\"\"Run all preprocessing steps\"\"\"\n",
    "        # Remove HTML\n",
    "        self.remove_html()\n",
    "        \n",
    "        # Detect code blocks\n",
    "        self.code_blocks = self.find_code_blocks()\n",
    "        \n",
    "        # Process code blocks into HTML format\n",
    "        self.process_code_blocks()\n",
    "        \n",
    "        # Clean up excessive whitespace\n",
    "        self.clean_whitespace()\n",
    "        self.split_text()\n",
    "\n",
    "        return self.cleaned_text.lower()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "def preprocess_blog_post(raw_text) -> str:\n",
    "    if type(raw_text) != str:\n",
    "        raw_text = raw_text['content'].iloc[0]\n",
    "\n",
    "    \"\"\"Preprocess the blog post text\"\"\"\n",
    "    processor = TextProcessor(raw_text)\n",
    "    processed_content = processor.preprocess()\n",
    "    return processed_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, ext in zip([toss_sample, daangn_sample, wooahan_sample], ['toss', 'daangn', 'wooahan']):\n",
    "    output = preprocess_blog_post(input)\n",
    "    save_sample(output, ext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
